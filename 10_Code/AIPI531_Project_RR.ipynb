{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/belladu0201/Deep_RL_Recommender_System/blob/main/10_Code/AIPI531_Project_RR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9kpAfWodatn",
        "outputId": "8c06b6cc-4b46-4359-8eec-123c4cbc509d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Colab Notebooks/AIPI 531/Final Project/SA2C_code/Kaggle\n",
            "data\t\t      report_SA2C.txt\t\t  SNQN_RR_FeatureVec_new.py\n",
            "DQN_NS.py\t      report_SNQN_FeatureVec.txt  SNQN_RR_FeatureVec.py\n",
            "NextItNetModules.py   SA2C_new.py\t\t  split_data.py\n",
            "pop.py\t\t      SA2C.py\t\t\t  test.py\n",
            "preprocess_kaggle.py  SASRecModules.py\t\t  utility.py\n",
            "__pycache__\t      SNQN_new.py\n",
            "replay_buffer.py      SNQN.py\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "PROJ_DIR = '/content/drive/MyDrive/Colab Notebooks/AIPI 531/Final Project/SA2C_code/Kaggle'\n",
        "# change current directory after mounting\n",
        "%cd $PROJ_DIR\n",
        "! ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pksoPQy_lDXL",
        "outputId": "64f1264b-a90f-4ecf-882c-3fb802a936cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-01 04:21:39.245829: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-01 04:21:40.667187: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO line 1:0: Not upgrading symbols because `tensorflow.compat.v1` was directly imported as `tf`.\n",
            "INFO line 2:0: Renamed 'tf.disable_v2_behavior' to 'tf.compat.v1.disable_v2_behavior'\n",
            "WARNING line 76:29: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "WARNING line 157:36: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "WARNING line 172:26: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "TensorFlow 2.0 Upgrade Script\n",
            "-----------------------------\n",
            "Converted 1 files\n",
            "Detected 3 issues that require attention\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "File: /content/drive/MyDrive/Colab Notebooks/AIPI 531/Final Project/SA2C_code/Kaggle/SNQN.py\n",
            "--------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/Colab Notebooks/AIPI 531/Final Project/SA2C_code/Kaggle/SNQN.py:76:29: WARNING: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "/content/drive/MyDrive/Colab Notebooks/AIPI 531/Final Project/SA2C_code/Kaggle/SNQN.py:157:36: WARNING: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "/content/drive/MyDrive/Colab Notebooks/AIPI 531/Final Project/SA2C_code/Kaggle/SNQN.py:172:26: WARNING: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "\n",
            "\n",
            "Make sure to read the detailed log 'report_SNQN_FeatureVec.txt'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!tf_upgrade_v2 \\\n",
        "  --infile '/content/drive/MyDrive/Colab Notebooks/AIPI 531/Final Project/SA2C_code/Kaggle/SNQN.py' \\\n",
        "  --outfile '/content/drive/MyDrive/Colab Notebooks/AIPI 531/Final Project/SA2C_code/Kaggle/SNQN_new.py' \\\n",
        "  --reportfile report_SNQN_FeatureVec.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmpjaaxCeAdL",
        "outputId": "374a7a62-c28d-42e3-c0a8-15a5eb60458d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-01 04:20:23.865155: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-01 04:20:25.324300: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO line 1:0: Not upgrading symbols because `tensorflow.compat.v1` was directly imported as `tf`.\n",
            "INFO line 2:0: Renamed 'tf.disable_v2_behavior' to 'tf.compat.v1.disable_v2_behavior'\n",
            "INFO line 103:27: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 106:13: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n",
            "INFO line 108:26: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 111:29: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "WARNING line 116:29: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "INFO line 130:20: Changed tf.to_float call to tf.cast(..., dtype=tf.float32).\n",
            "INFO line 141:25: `name` passed to `name_scope`. Because you may be re-entering an existing scope, it is not safe to convert automatically,  the v2 name_scope does not support re-entering scopes by name.\n",
            "\n",
            "INFO line 141:25: Renamed 'tf.name_scope' to 'tf.compat.v1.name_scope'\n",
            "INFO line 145:28: Renamed 'tf.truncated_normal' to 'tf.random.truncated_normal'\n",
            "INFO line 149:31: Added keywords to args of function 'tf.nn.conv2d'\n",
            "INFO line 149:31: Renamed keyword argument for tf.nn.conv2d from filter to filters\n",
            "INFO line 161:33: Added keywords to args of function 'tf.nn.max_pool'\n",
            "INFO line 161:33: Renamed keyword argument for tf.nn.max_pool from value to input\n",
            "INFO line 161:33: Renamed 'tf.nn.max_pool' to 'tf.nn.max_pool2d'\n",
            "INFO line 177:21: `name` passed to `name_scope`. Because you may be re-entering an existing scope, it is not safe to convert automatically,  the v2 name_scope does not support re-entering scopes by name.\n",
            "\n",
            "INFO line 177:21: Renamed 'tf.name_scope' to 'tf.compat.v1.name_scope'\n",
            "INFO line 180:24: Renamed 'tf.truncated_normal' to 'tf.random.truncated_normal'\n",
            "INFO line 183:27: Added keywords to args of function 'tf.nn.conv2d'\n",
            "INFO line 183:27: Renamed keyword argument for tf.nn.conv2d from filter to filters\n",
            "INFO line 197:21: `name` passed to `name_scope`. Because you may be re-entering an existing scope, it is not safe to convert automatically,  the v2 name_scope does not support re-entering scopes by name.\n",
            "\n",
            "INFO line 197:21: Renamed 'tf.name_scope' to 'tf.compat.v1.name_scope'\n",
            "INFO line 198:41: Renamed 'tf.layers.dropout' to 'tf.compat.v1.layers.dropout'\n",
            "INFO line 206:20: Changed tf.to_float call to tf.cast(..., dtype=tf.float32).\n",
            "WARNING line 223:36: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "WARNING line 244:26: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "INFO line 254:20: Changed tf.to_float call to tf.cast(..., dtype=tf.float32).\n",
            "INFO line 257:27: Renamed 'tf.layers.dropout' to 'tf.compat.v1.layers.dropout'\n",
            "INFO line 267:25: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n",
            "INFO line 320:27: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 322:36: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 324:29: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 325:37: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 328:26: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 329:28: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 331:36: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 332:44: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 368:23: Renamed 'tf.train.AdamOptimizer' to 'tf.compat.v1.train.AdamOptimizer'\n",
            "INFO line 373:17: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n",
            "INFO line 375:20: Renamed 'tf.random_normal' to 'tf.random.normal'\n",
            "INFO line 379:20: Renamed 'tf.random_normal' to 'tf.random.normal'\n",
            "INFO line 496:4: Renamed 'tf.reset_default_graph' to 'tf.compat.v1.reset_default_graph'\n",
            "INFO line 521:9: Renamed 'tf.Session' to 'tf.compat.v1.Session'\n",
            "INFO line 523:17: Renamed 'tf.global_variables_initializer' to 'tf.compat.v1.global_variables_initializer'\n",
            "TensorFlow 2.0 Upgrade Script\n",
            "-----------------------------\n",
            "Converted 1 files\n",
            "Detected 3 issues that require attention\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "File: /content/drive/MyDrive/Colab Notebooks/AIPI 531/Final Project/SA2C_code/Kaggle/SNQN_RR_FeatureVec.py\n",
            "--------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/Colab Notebooks/AIPI 531/Final Project/SA2C_code/Kaggle/SNQN_RR_FeatureVec.py:116:29: WARNING: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "/content/drive/MyDrive/Colab Notebooks/AIPI 531/Final Project/SA2C_code/Kaggle/SNQN_RR_FeatureVec.py:223:36: WARNING: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "/content/drive/MyDrive/Colab Notebooks/AIPI 531/Final Project/SA2C_code/Kaggle/SNQN_RR_FeatureVec.py:244:26: WARNING: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "\n",
            "\n",
            "Make sure to read the detailed log 'report_SNQN_FeatureVec.txt'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!tf_upgrade_v2 \\\n",
        "  --infile '/content/drive/MyDrive/Colab Notebooks/AIPI 531/Final Project/SA2C_code/Kaggle/SNQN_RR_FeatureVec.py' \\\n",
        "  --outfile '/content/drive/MyDrive/Colab Notebooks/AIPI 531/Final Project/SA2C_code/Kaggle/SNQN_RR_FeatureVec_new.py' \\\n",
        "  --reportfile report_SNQN_FeatureVec.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P67I7JeRiEaG",
        "outputId": "91de24fc-b7b2-4747-a000-70dce06ce29f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Collecting trfl\n",
            "  Downloading trfl-1.2.0-py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from trfl) (1.16.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from trfl) (1.14.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from trfl) (1.4.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from trfl) (0.1.8)\n",
            "Installing collected packages: trfl\n",
            "Successfully installed trfl-1.2.0\n"
          ]
        }
      ],
      "source": [
        "! pip install pandas trfl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9P5JGc-k0nO",
        "outputId": "fea4ea5f-9cc0-4576-ba7f-b7d34446b07e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-04-29 04:08:21.136749: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-29 04:08:22.312640: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "/content/drive/MyDrive/Colab Notebooks/AIPI 531/Final Project/SA2C_code/Kaggle/SNQN_RR_FeatureVec_new.py:122: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/Colab Notebooks/AIPI 531/Final Project/SA2C_code/Kaggle/SNQN_RR_FeatureVec_new.py:121: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/layers/rnn/legacy_cells.py:584: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/layers/rnn/legacy_cells.py:598: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "/content/drive/MyDrive/Colab Notebooks/AIPI 531/Final Project/SA2C_code/Kaggle/SNQN_RR_FeatureVec_new.py:294: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(\n",
            "/content/drive/MyDrive/Colab Notebooks/AIPI 531/Final Project/SA2C_code/Kaggle/SNQN_RR_FeatureVec_new.py:298: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2 = tf.compat.v1.layers.dense(\n",
            "/content/drive/MyDrive/Colab Notebooks/AIPI 531/Final Project/SA2C_code/Kaggle/SNQN_RR_FeatureVec_new.py:302: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.w_f = tf.compat.v1.layers.dense(\n",
            "2023-04-29 04:08:42.105519: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-04-29 04:08:42.690870: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-04-29 04:08:42.691179: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-04-29 04:08:42.692044: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-04-29 04:08:42.692279: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-04-29 04:08:42.692483: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-04-29 04:08:45.157345: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-04-29 04:08:45.157663: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-04-29 04:08:45.157895: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-04-29 04:08:45.158081: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-04-29 04:08:45.158126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13678 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2023-04-29 04:08:45.744906: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 4.600000\n",
            "clicks hr ndcg @ 5 : 0.000110, 0.000075\n",
            "purchase hr and ndcg @5 : 0.000378, 0.000192\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 6.200000\n",
            "clicks hr ndcg @ 10 : 0.000178, 0.000096\n",
            "purchase hr and ndcg @10 : 0.000378, 0.000192\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 7.600000\n",
            "clicks hr ndcg @ 15 : 0.000237, 0.000111\n",
            "purchase hr and ndcg @15 : 0.000378, 0.000192\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 9.400000\n",
            "clicks hr ndcg @ 20 : 0.000313, 0.000129\n",
            "purchase hr and ndcg @20 : 0.000378, 0.000192\n",
            "#############################################################\n",
            "the loss in 200th batch is: 10.839041\n",
            "the loss in 400th batch is: 10.317200\n",
            "the loss in 600th batch is: 10.612482\n",
            "the loss in 800th batch is: 10.296825\n",
            "the loss in 1000th batch is: 10.099700\n",
            "the loss in 1200th batch is: 10.152332\n",
            "the loss in 1400th batch is: 10.012610\n",
            "the loss in 1600th batch is: 9.448859\n",
            "the loss in 1800th batch is: 9.395426\n",
            "the loss in 2000th batch is: 9.862986\n",
            "the loss in 2200th batch is: 9.494584\n",
            "the loss in 2400th batch is: 9.114390\n",
            "the loss in 2600th batch is: 9.397276\n",
            "the loss in 2800th batch is: 8.934057\n",
            "the loss in 3000th batch is: 9.110419\n",
            "the loss in 3200th batch is: 8.914892\n",
            "the loss in 3400th batch is: 8.585890\n",
            "the loss in 3600th batch is: 8.973169\n",
            "the loss in 3800th batch is: 8.680499\n",
            "the loss in 4000th batch is: 8.484572\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 4436.200000\n",
            "clicks hr ndcg @ 5 : 0.124727, 0.094501\n",
            "purchase hr and ndcg @5 : 0.280665, 0.223093\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 5383.000000\n",
            "clicks hr ndcg @ 10 : 0.154937, 0.104285\n",
            "purchase hr and ndcg @10 : 0.324513, 0.237313\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 5940.000000\n",
            "clicks hr ndcg @ 15 : 0.172941, 0.109058\n",
            "purchase hr and ndcg @15 : 0.349272, 0.243901\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 6330.000000\n",
            "clicks hr ndcg @ 20 : 0.186043, 0.112152\n",
            "purchase hr and ndcg @20 : 0.364392, 0.247455\n",
            "#############################################################\n",
            "the loss in 4200th batch is: 8.834645\n",
            "the loss in 4400th batch is: 8.314168\n",
            "the loss in 4600th batch is: 7.784096\n",
            "the loss in 4800th batch is: 8.513685\n",
            "the loss in 5000th batch is: 8.174412\n",
            "the loss in 5200th batch is: 8.149987\n",
            "the loss in 5400th batch is: 8.195355\n",
            "the loss in 5600th batch is: 8.087030\n",
            "the loss in 5800th batch is: 7.594770\n",
            "the loss in 6000th batch is: 7.916823\n",
            "the loss in 6200th batch is: 7.858956\n",
            "the loss in 6400th batch is: 7.800028\n",
            "the loss in 6600th batch is: 7.837386\n",
            "the loss in 6800th batch is: 7.655406\n",
            "the loss in 7000th batch is: 7.295758\n",
            "the loss in 7200th batch is: 7.317465\n",
            "the loss in 7400th batch is: 7.485460\n",
            "the loss in 7600th batch is: 7.682627\n",
            "the loss in 7800th batch is: 7.123072\n",
            "the loss in 8000th batch is: 7.517581\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 6055.800000\n",
            "clicks hr ndcg @ 5 : 0.174159, 0.130462\n",
            "purchase hr and ndcg @5 : 0.365715, 0.287896\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 7409.000000\n",
            "clicks hr ndcg @ 10 : 0.218290, 0.144746\n",
            "purchase hr and ndcg @10 : 0.424116, 0.306880\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 8143.200000\n",
            "clicks hr ndcg @ 15 : 0.242938, 0.151273\n",
            "purchase hr and ndcg @15 : 0.452655, 0.314454\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 8650.600000\n",
            "clicks hr ndcg @ 20 : 0.260452, 0.155413\n",
            "purchase hr and ndcg @20 : 0.470232, 0.318619\n",
            "#############################################################\n",
            "the loss in 8200th batch is: 7.396327\n",
            "the loss in 8400th batch is: 7.512034\n",
            "the loss in 8600th batch is: 7.357805\n",
            "the loss in 8800th batch is: 7.227684\n",
            "the loss in 9000th batch is: 7.209519\n",
            "the loss in 9200th batch is: 6.784718\n",
            "the loss in 9400th batch is: 7.392872\n",
            "the loss in 9600th batch is: 6.943258\n",
            "the loss in 9800th batch is: 7.006492\n",
            "the loss in 10000th batch is: 7.254798\n",
            "the loss in 10200th batch is: 6.316532\n",
            "the loss in 10400th batch is: 6.780774\n",
            "the loss in 10600th batch is: 7.185233\n",
            "the loss in 10800th batch is: 6.422863\n",
            "the loss in 11000th batch is: 6.977721\n",
            "the loss in 11200th batch is: 6.644858\n",
            "the loss in 11400th batch is: 6.720266\n",
            "the loss in 11600th batch is: 6.755087\n",
            "the loss in 11800th batch is: 6.948694\n",
            "the loss in 12000th batch is: 7.031447\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 6657.400000\n",
            "clicks hr ndcg @ 5 : 0.192526, 0.143544\n",
            "purchase hr and ndcg @5 : 0.397278, 0.312154\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 8172.400000\n",
            "clicks hr ndcg @ 10 : 0.243707, 0.160120\n",
            "purchase hr and ndcg @10 : 0.454734, 0.330796\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 9019.200000\n",
            "clicks hr ndcg @ 15 : 0.272057, 0.167632\n",
            "purchase hr and ndcg @15 : 0.487998, 0.339620\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 9613.200000\n",
            "clicks hr ndcg @ 20 : 0.291963, 0.172340\n",
            "purchase hr and ndcg @20 : 0.511246, 0.345106\n",
            "#############################################################\n",
            "the loss in 12200th batch is: 6.834641\n",
            "the loss in 12400th batch is: 6.488188\n",
            "the loss in 12600th batch is: 6.240452\n",
            "the loss in 12800th batch is: 6.336985\n",
            "the loss in 13000th batch is: 6.544296\n",
            "the loss in 13200th batch is: 6.352902\n",
            "the loss in 13400th batch is: 6.492264\n",
            "the loss in 13600th batch is: 6.211607\n",
            "the loss in 13800th batch is: 6.265075\n",
            "the loss in 14000th batch is: 6.217001\n",
            "the loss in 14200th batch is: 6.594361\n",
            "the loss in 14400th batch is: 5.851827\n",
            "the loss in 14600th batch is: 6.208966\n",
            "the loss in 14800th batch is: 6.016685\n",
            "the loss in 15000th batch is: 5.995447\n",
            "the loss in 15200th batch is: 6.249801\n",
            "the loss in 15400th batch is: 6.329788\n",
            "the loss in 15600th batch is: 6.472445\n",
            "the loss in 15800th batch is: 5.937142\n",
            "the loss in 16000th batch is: 5.972662\n"
          ]
        }
      ],
      "source": [
        "! python SNQN_new.py --model=GRU --epoch=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcuregszIjZJ",
        "outputId": "c5f7a05c-6964-4803-8430-8d04e8f5af8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-01 06:45:03.170329: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-01 06:45:04.212782: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "/content/drive/MyDrive/Colab Notebooks/AIPI 531/Final Project/SA2C_code/Kaggle/SNQN_new.py:80: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/Colab Notebooks/AIPI 531/Final Project/SA2C_code/Kaggle/SNQN_new.py:79: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/layers/rnn/legacy_cells.py:584: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/layers/rnn/legacy_cells.py:598: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "/content/drive/MyDrive/Colab Notebooks/AIPI 531/Final Project/SA2C_code/Kaggle/SNQN_new.py:207: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(\n",
            "/content/drive/MyDrive/Colab Notebooks/AIPI 531/Final Project/SA2C_code/Kaggle/SNQN_new.py:211: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2 = tf.compat.v1.layers.dense(\n",
            "2023-05-01 06:45:11.579567: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-01 06:45:11.619878: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-01 06:45:11.620658: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-01 06:45:11.621564: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-01 06:45:11.621845: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-01 06:45:11.622060: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-01 06:45:12.969899: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-01 06:45:12.970274: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-01 06:45:12.970510: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-01 06:45:12.970693: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-05-01 06:45:12.970739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13678 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2023-05-01 06:45:13.005354: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 1.400000\n",
            "clicks hr ndcg @ 5 : 0.000059, 0.000034\n",
            "purchase hr and ndcg @5 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 2.600000\n",
            "clicks hr ndcg @ 10 : 0.000110, 0.000049\n",
            "purchase hr and ndcg @10 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 4.400000\n",
            "clicks hr ndcg @ 15 : 0.000144, 0.000058\n",
            "purchase hr and ndcg @15 : 0.000189, 0.000050\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 6.000000\n",
            "clicks hr ndcg @ 20 : 0.000211, 0.000074\n",
            "purchase hr and ndcg @20 : 0.000189, 0.000050\n",
            "#############################################################\n",
            "the loss in 200th batch is: 10.491442\n",
            "the loss in 400th batch is: 10.668275\n",
            "the loss in 600th batch is: 10.277361\n",
            "the loss in 800th batch is: 10.075214\n",
            "the loss in 1000th batch is: 9.864118\n",
            "the loss in 1200th batch is: 10.079099\n",
            "the loss in 1400th batch is: 9.423697\n",
            "the loss in 1600th batch is: 8.991639\n",
            "the loss in 1800th batch is: 9.600970\n",
            "the loss in 2000th batch is: 9.331326\n",
            "the loss in 2200th batch is: 8.734925\n",
            "the loss in 2400th batch is: 8.668464\n",
            "the loss in 2600th batch is: 8.374595\n",
            "the loss in 2800th batch is: 8.266227\n",
            "the loss in 3000th batch is: 8.120722\n",
            "the loss in 3200th batch is: 8.251225\n",
            "the loss in 3400th batch is: 8.504484\n",
            "the loss in 3600th batch is: 7.900362\n",
            "the loss in 3800th batch is: 7.813877\n",
            "the loss in 4000th batch is: 7.722189\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 5504.800000\n",
            "clicks hr ndcg @ 5 : 0.154760, 0.121851\n",
            "purchase hr and ndcg @5 : 0.348327, 0.294275\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 6450.000000\n",
            "clicks hr ndcg @ 10 : 0.185874, 0.131917\n",
            "purchase hr and ndcg @10 : 0.387828, 0.307112\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 7014.000000\n",
            "clicks hr ndcg @ 15 : 0.204216, 0.136761\n",
            "purchase hr and ndcg @15 : 0.412398, 0.313572\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 7408.200000\n",
            "clicks hr ndcg @ 20 : 0.217664, 0.139937\n",
            "purchase hr and ndcg @20 : 0.426762, 0.316975\n",
            "#############################################################\n",
            "the loss in 4200th batch is: 7.189055\n",
            "the loss in 4400th batch is: 7.395443\n",
            "the loss in 4600th batch is: 7.159760\n",
            "the loss in 4800th batch is: 6.994061\n",
            "the loss in 5000th batch is: 6.935145\n",
            "the loss in 5200th batch is: 6.845492\n",
            "the loss in 5400th batch is: 7.432989\n",
            "the loss in 5600th batch is: 6.750286\n",
            "the loss in 5800th batch is: 6.953674\n",
            "the loss in 6000th batch is: 6.997913\n",
            "the loss in 6200th batch is: 6.906713\n",
            "the loss in 6400th batch is: 6.852166\n",
            "the loss in 6600th batch is: 6.822448\n",
            "the loss in 6800th batch is: 6.818631\n",
            "the loss in 7000th batch is: 6.476360\n",
            "the loss in 7200th batch is: 6.203366\n",
            "the loss in 7400th batch is: 6.369277\n",
            "the loss in 7600th batch is: 6.684971\n",
            "the loss in 7800th batch is: 6.499208\n",
            "the loss in 8000th batch is: 6.302542\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 7371.600000\n",
            "clicks hr ndcg @ 5 : 0.210243, 0.164951\n",
            "purchase hr and ndcg @5 : 0.453033, 0.380105\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 8544.800000\n",
            "clicks hr ndcg @ 10 : 0.249894, 0.177785\n",
            "purchase hr and ndcg @10 : 0.497448, 0.394525\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 9189.200000\n",
            "clicks hr ndcg @ 15 : 0.272226, 0.183705\n",
            "purchase hr and ndcg @15 : 0.519373, 0.400289\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 9647.400000\n",
            "clicks hr ndcg @ 20 : 0.287745, 0.187374\n",
            "purchase hr and ndcg @20 : 0.536572, 0.404354\n",
            "#############################################################\n",
            "the loss in 8200th batch is: 6.099860\n",
            "the loss in 8400th batch is: 6.314453\n",
            "the loss in 8600th batch is: 6.500594\n",
            "the loss in 8800th batch is: 6.419089\n",
            "the loss in 9000th batch is: 5.815701\n",
            "the loss in 9200th batch is: 5.839789\n",
            "the loss in 9400th batch is: 6.151280\n",
            "the loss in 9600th batch is: 6.083085\n",
            "the loss in 9800th batch is: 6.197161\n",
            "the loss in 10000th batch is: 5.916913\n",
            "the loss in 10200th batch is: 5.762587\n",
            "the loss in 10400th batch is: 5.995911\n",
            "the loss in 10600th batch is: 6.419263\n",
            "the loss in 10800th batch is: 6.384787\n",
            "the loss in 11000th batch is: 5.559968\n",
            "the loss in 11200th batch is: 5.675771\n",
            "the loss in 11400th batch is: 5.995345\n",
            "the loss in 11600th batch is: 5.582155\n",
            "the loss in 11800th batch is: 6.111606\n",
            "the loss in 12000th batch is: 5.250821\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 7702.400000\n",
            "clicks hr ndcg @ 5 : 0.222491, 0.173327\n",
            "purchase hr and ndcg @5 : 0.460782, 0.382594\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 8994.400000\n",
            "clicks hr ndcg @ 10 : 0.265980, 0.187403\n",
            "purchase hr and ndcg @10 : 0.510490, 0.398646\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 9729.400000\n",
            "clicks hr ndcg @ 15 : 0.290704, 0.193952\n",
            "purchase hr and ndcg @15 : 0.538840, 0.406169\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 10225.800000\n",
            "clicks hr ndcg @ 20 : 0.307922, 0.198021\n",
            "purchase hr and ndcg @20 : 0.555661, 0.410135\n",
            "#############################################################\n",
            "the loss in 12200th batch is: 5.705418\n",
            "the loss in 12400th batch is: 5.766516\n",
            "the loss in 12600th batch is: 5.577910\n",
            "the loss in 12800th batch is: 5.549993\n",
            "the loss in 13000th batch is: 5.845812\n",
            "the loss in 13200th batch is: 5.777842\n",
            "the loss in 13400th batch is: 5.620402\n",
            "the loss in 13600th batch is: 5.507872\n",
            "the loss in 13800th batch is: 5.371011\n",
            "the loss in 14000th batch is: 4.908694\n",
            "the loss in 14200th batch is: 5.378427\n",
            "the loss in 14400th batch is: 4.950961\n",
            "the loss in 14600th batch is: 5.449141\n",
            "the loss in 14800th batch is: 5.758972\n",
            "the loss in 15000th batch is: 5.266221\n",
            "the loss in 15200th batch is: 5.464267\n",
            "the loss in 15400th batch is: 5.297099\n",
            "the loss in 15600th batch is: 5.707600\n",
            "the loss in 15800th batch is: 5.592139\n",
            "the loss in 16000th batch is: 5.599976\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 7725.000000\n",
            "clicks hr ndcg @ 5 : 0.223700, 0.173094\n",
            "purchase hr and ndcg @5 : 0.459648, 0.377822\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 9015.800000\n",
            "clicks hr ndcg @ 10 : 0.267222, 0.187191\n",
            "purchase hr and ndcg @10 : 0.508978, 0.393771\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 9772.200000\n",
            "clicks hr ndcg @ 15 : 0.292893, 0.193988\n",
            "purchase hr and ndcg @15 : 0.537139, 0.401258\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 10329.200000\n",
            "clicks hr ndcg @ 20 : 0.311827, 0.198464\n",
            "purchase hr and ndcg @20 : 0.557740, 0.406131\n",
            "#############################################################\n",
            "the loss in 16200th batch is: 5.127710\n",
            "the loss in 16400th batch is: 5.277160\n",
            "the loss in 16600th batch is: 5.004559\n",
            "the loss in 16800th batch is: 5.375435\n",
            "the loss in 17000th batch is: 5.360450\n",
            "the loss in 17200th batch is: 5.158172\n",
            "the loss in 17400th batch is: 5.322412\n",
            "the loss in 17600th batch is: 5.420489\n",
            "the loss in 17800th batch is: 5.024101\n",
            "the loss in 18000th batch is: 5.155421\n",
            "the loss in 18200th batch is: 4.958363\n",
            "the loss in 18400th batch is: 4.908526\n",
            "the loss in 18600th batch is: 4.685524\n",
            "the loss in 18800th batch is: 5.446716\n",
            "the loss in 19000th batch is: 5.226193\n",
            "the loss in 19200th batch is: 5.515488\n"
          ]
        }
      ],
      "source": [
        "! python SNQN_RR_FeatureVec_new.py --model=GRU --epoch=5"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ORauI7Vti5Cv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}