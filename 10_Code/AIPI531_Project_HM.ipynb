{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/belladu0201/Deep_RL_Recommender_System/blob/main/10_Code/AIPI531_Project_HM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9kpAfWodatn",
        "outputId": "bec164c6-10c4-4936-8fb8-62f945768de6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/.shortcut-targets-by-id/1HIjrgz2KrB4wLCZasrYeKTXkE-b6--I_/HM\n",
            " data\t\t\t       replay_buffer.py\n",
            "'H&M_EDA_articles.ipynb'       report_SNQN_FeatureVec.txt\n",
            "'H&M_EDA_customer.ipynb'       SASRecModules.py\n",
            "'H&M_EDA_transactions.ipynb'   SNQN_new.py\n",
            " NextItNetModules.py\t       SNQN.py\n",
            " pop_dict.txt\t\t       SNQN_RR_FeatureVec_new.py\n",
            " pop.py\t\t\t       SNQN_RR_FeatureVec.py\n",
            " pre_processing.py\t       utility.py\n",
            " __pycache__\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive folder\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "drive.mount('/content/drive')\n",
        "PROJ_DIR = '/content/drive/MyDrive/HM/'\n",
        "# change current directory after mounting\n",
        "%cd $PROJ_DIR\n",
        "! ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P67I7JeRiEaG",
        "outputId": "27a7a55b-c53e-4cdf-a9a3-e246754dcebb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Collecting trfl\n",
            "  Downloading trfl-1.2.0-py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from trfl) (1.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from trfl) (1.16.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from trfl) (1.4.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from trfl) (0.1.8)\n",
            "Installing collected packages: trfl\n",
            "Successfully installed trfl-1.2.0\n"
          ]
        }
      ],
      "source": [
        "! pip install pandas trfl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmpjaaxCeAdL",
        "outputId": "d6ef700e-069f-4d10-ea48-0377f1cfbee2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-03 02:38:12.015169: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-05-03 02:38:12.068264: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-03 02:38:13.113621: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO line 1:0: Not upgrading symbols because `tensorflow.compat.v1` was directly imported as `tf`.\n",
            "INFO line 2:0: Renamed 'tf.disable_v2_behavior' to 'tf.compat.v1.disable_v2_behavior'\n",
            "INFO line 103:27: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 106:13: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n",
            "INFO line 108:26: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 111:29: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "WARNING line 116:29: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "INFO line 130:20: Changed tf.to_float call to tf.cast(..., dtype=tf.float32).\n",
            "INFO line 141:25: `name` passed to `name_scope`. Because you may be re-entering an existing scope, it is not safe to convert automatically,  the v2 name_scope does not support re-entering scopes by name.\n",
            "\n",
            "INFO line 141:25: Renamed 'tf.name_scope' to 'tf.compat.v1.name_scope'\n",
            "INFO line 145:28: Renamed 'tf.truncated_normal' to 'tf.random.truncated_normal'\n",
            "INFO line 149:31: Added keywords to args of function 'tf.nn.conv2d'\n",
            "INFO line 149:31: Renamed keyword argument for tf.nn.conv2d from filter to filters\n",
            "INFO line 161:33: Added keywords to args of function 'tf.nn.max_pool'\n",
            "INFO line 161:33: Renamed keyword argument for tf.nn.max_pool from value to input\n",
            "INFO line 161:33: Renamed 'tf.nn.max_pool' to 'tf.nn.max_pool2d'\n",
            "INFO line 177:21: `name` passed to `name_scope`. Because you may be re-entering an existing scope, it is not safe to convert automatically,  the v2 name_scope does not support re-entering scopes by name.\n",
            "\n",
            "INFO line 177:21: Renamed 'tf.name_scope' to 'tf.compat.v1.name_scope'\n",
            "INFO line 180:24: Renamed 'tf.truncated_normal' to 'tf.random.truncated_normal'\n",
            "INFO line 183:27: Added keywords to args of function 'tf.nn.conv2d'\n",
            "INFO line 183:27: Renamed keyword argument for tf.nn.conv2d from filter to filters\n",
            "INFO line 197:21: `name` passed to `name_scope`. Because you may be re-entering an existing scope, it is not safe to convert automatically,  the v2 name_scope does not support re-entering scopes by name.\n",
            "\n",
            "INFO line 197:21: Renamed 'tf.name_scope' to 'tf.compat.v1.name_scope'\n",
            "INFO line 198:41: Renamed 'tf.layers.dropout' to 'tf.compat.v1.layers.dropout'\n",
            "INFO line 206:20: Changed tf.to_float call to tf.cast(..., dtype=tf.float32).\n",
            "WARNING line 223:36: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "WARNING line 244:26: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "INFO line 254:20: Changed tf.to_float call to tf.cast(..., dtype=tf.float32).\n",
            "INFO line 257:27: Renamed 'tf.layers.dropout' to 'tf.compat.v1.layers.dropout'\n",
            "INFO line 267:25: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n",
            "INFO line 320:27: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 322:36: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 324:29: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 325:37: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 328:26: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 329:28: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 331:36: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 332:44: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 368:23: Renamed 'tf.train.AdamOptimizer' to 'tf.compat.v1.train.AdamOptimizer'\n",
            "INFO line 373:17: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n",
            "INFO line 375:20: Renamed 'tf.random_normal' to 'tf.random.normal'\n",
            "INFO line 379:20: Renamed 'tf.random_normal' to 'tf.random.normal'\n",
            "INFO line 496:4: Renamed 'tf.reset_default_graph' to 'tf.compat.v1.reset_default_graph'\n",
            "INFO line 521:9: Renamed 'tf.Session' to 'tf.compat.v1.Session'\n",
            "INFO line 523:17: Renamed 'tf.global_variables_initializer' to 'tf.compat.v1.global_variables_initializer'\n",
            "TensorFlow 2.0 Upgrade Script\n",
            "-----------------------------\n",
            "Converted 1 files\n",
            "Detected 3 issues that require attention\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "File: /content/drive/MyDrive/HM/SNQN_RR_FeatureVec.py\n",
            "--------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/HM/SNQN_RR_FeatureVec.py:116:29: WARNING: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "/content/drive/MyDrive/HM/SNQN_RR_FeatureVec.py:223:36: WARNING: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "/content/drive/MyDrive/HM/SNQN_RR_FeatureVec.py:244:26: WARNING: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "\n",
            "\n",
            "Make sure to read the detailed log 'report_SNQN_FeatureVec.txt'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!tf_upgrade_v2 \\\n",
        "  --infile '/content/drive/MyDrive/HM/SNQN_RR_FeatureVec.py' \\\n",
        "  --outfile '/content/drive/MyDrive/HM/SNQN_RR_FeatureVec_new.py' \\\n",
        "  --reportfile report_SNQN_FeatureVec.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9P5JGc-k0nO",
        "outputId": "4b044870-9a0a-4697-e60a-fdce84eac2bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-03 02:38:24.408983: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-05-03 02:38:24.462672: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-03 02:38:25.564838: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "/content/drive/.shortcut-targets-by-id/1HIjrgz2KrB4wLCZasrYeKTXkE-b6--I_/HM/SNQN_RR_FeatureVec_new.py:122: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n",
            "WARNING:tensorflow:From /content/drive/.shortcut-targets-by-id/1HIjrgz2KrB4wLCZasrYeKTXkE-b6--I_/HM/SNQN_RR_FeatureVec_new.py:121: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/layers/rnn/legacy_cells.py:584: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/layers/rnn/legacy_cells.py:598: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "/content/drive/.shortcut-targets-by-id/1HIjrgz2KrB4wLCZasrYeKTXkE-b6--I_/HM/SNQN_RR_FeatureVec_new.py:294: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(\n",
            "/content/drive/.shortcut-targets-by-id/1HIjrgz2KrB4wLCZasrYeKTXkE-b6--I_/HM/SNQN_RR_FeatureVec_new.py:298: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2 = tf.compat.v1.layers.dense(\n",
            "/content/drive/.shortcut-targets-by-id/1HIjrgz2KrB4wLCZasrYeKTXkE-b6--I_/HM/SNQN_RR_FeatureVec_new.py:302: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.w_f = tf.compat.v1.layers.dense(\n",
            "2023-05-03 02:38:50.141587: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-05-03 02:38:50.141688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38286 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n",
            "2023-05-03 02:38:50.516095: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
            "2023-05-03 02:38:55.765552: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
            "#############################################################\n",
            "total clicks: 196613, total purchase:340292\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 52.000000\n",
            "clicks hr ndcg @ 5 : 0.000127, 0.000073\n",
            "purchase hr and ndcg @5 : 0.000138, 0.000080\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 103.200000\n",
            "clicks hr ndcg @ 10 : 0.000259, 0.000114\n",
            "purchase hr and ndcg @10 : 0.000273, 0.000123\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 144.800000\n",
            "clicks hr ndcg @ 15 : 0.000376, 0.000144\n",
            "purchase hr and ndcg @15 : 0.000382, 0.000152\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 196.200000\n",
            "clicks hr ndcg @ 20 : 0.000539, 0.000183\n",
            "purchase hr and ndcg @20 : 0.000514, 0.000183\n",
            "#############################################################\n",
            "the loss in 200th batch is: 10.341968\n",
            "the loss in 400th batch is: 11.873026\n",
            "the loss in 600th batch is: 9.804504\n",
            "the loss in 800th batch is: 9.816662\n",
            "the loss in 1000th batch is: 9.590275\n",
            "the loss in 1200th batch is: 9.738022\n",
            "the loss in 1400th batch is: 10.016935\n",
            "the loss in 1600th batch is: 9.517743\n",
            "the loss in 1800th batch is: 9.604262\n",
            "the loss in 2000th batch is: 9.503578\n",
            "the loss in 2200th batch is: 9.598590\n",
            "the loss in 2400th batch is: 9.592832\n",
            "#############################################################\n",
            "total clicks: 196613, total purchase:340292\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 5098.800000\n",
            "clicks hr ndcg @ 5 : 0.011210, 0.007182\n",
            "purchase hr and ndcg @5 : 0.013688, 0.008921\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 8553.800000\n",
            "clicks hr ndcg @ 10 : 0.017924, 0.009338\n",
            "purchase hr and ndcg @10 : 0.023065, 0.011917\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 11519.200000\n",
            "clicks hr ndcg @ 15 : 0.023478, 0.010804\n",
            "purchase hr and ndcg @15 : 0.031138, 0.014049\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 14134.000000\n",
            "clicks hr ndcg @ 20 : 0.028711, 0.012039\n",
            "purchase hr and ndcg @20 : 0.038217, 0.015719\n",
            "#############################################################\n",
            "the loss in 2600th batch is: 9.578030\n",
            "the loss in 2800th batch is: 9.452679\n",
            "the loss in 3000th batch is: 9.485786\n",
            "the loss in 3200th batch is: 9.369007\n",
            "the loss in 3400th batch is: 9.366173\n",
            "the loss in 3600th batch is: 9.405396\n",
            "the loss in 3800th batch is: 9.561861\n",
            "the loss in 4000th batch is: 9.293208\n",
            "the loss in 4200th batch is: 9.258239\n",
            "the loss in 4400th batch is: 9.462617\n",
            "the loss in 4600th batch is: 9.451992\n",
            "the loss in 4800th batch is: 9.315571\n",
            "#############################################################\n",
            "total clicks: 196613, total purchase:340292\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 10457.600000\n",
            "clicks hr ndcg @ 5 : 0.021021, 0.014273\n",
            "purchase hr and ndcg @5 : 0.028302, 0.019004\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 16140.400000\n",
            "clicks hr ndcg @ 10 : 0.032104, 0.017839\n",
            "purchase hr and ndcg @10 : 0.043721, 0.023954\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 20579.600000\n",
            "clicks hr ndcg @ 15 : 0.041467, 0.020310\n",
            "purchase hr and ndcg @15 : 0.055685, 0.027113\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 24476.400000\n",
            "clicks hr ndcg @ 20 : 0.049117, 0.022116\n",
            "purchase hr and ndcg @20 : 0.066252, 0.029606\n",
            "#############################################################\n",
            "the loss in 5000th batch is: 9.046410\n",
            "the loss in 5200th batch is: 9.324831\n",
            "the loss in 5400th batch is: 9.106538\n",
            "the loss in 5600th batch is: 9.224068\n",
            "the loss in 5800th batch is: 9.297731\n",
            "the loss in 6000th batch is: 9.008923\n",
            "the loss in 6200th batch is: 9.278789\n",
            "the loss in 6400th batch is: 9.198376\n",
            "the loss in 6600th batch is: 8.956176\n",
            "the loss in 6800th batch is: 9.343791\n",
            "the loss in 7000th batch is: 9.034739\n",
            "the loss in 7200th batch is: 9.108106\n",
            "#############################################################\n",
            "total clicks: 196613, total purchase:340292\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 13735.200000\n",
            "clicks hr ndcg @ 5 : 0.026860, 0.018725\n",
            "purchase hr and ndcg @5 : 0.037259, 0.025799\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 20421.000000\n",
            "clicks hr ndcg @ 10 : 0.040435, 0.023077\n",
            "purchase hr and ndcg @10 : 0.055338, 0.031606\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 25785.000000\n",
            "clicks hr ndcg @ 15 : 0.051039, 0.025878\n",
            "purchase hr and ndcg @15 : 0.069875, 0.035450\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 30167.800000\n",
            "clicks hr ndcg @ 20 : 0.060037, 0.028000\n",
            "purchase hr and ndcg @20 : 0.081715, 0.038246\n",
            "#############################################################\n",
            "the loss in 7400th batch is: 8.937485\n",
            "the loss in 7600th batch is: 9.047400\n",
            "the loss in 7800th batch is: 9.178421\n",
            "the loss in 8000th batch is: 8.794861\n",
            "the loss in 8200th batch is: 9.211266\n",
            "the loss in 8400th batch is: 8.909084\n",
            "the loss in 8600th batch is: 9.091458\n",
            "the loss in 8800th batch is: 9.176779\n",
            "the loss in 9000th batch is: 9.174873\n",
            "the loss in 9200th batch is: 8.972645\n",
            "the loss in 9400th batch is: 8.942785\n",
            "the loss in 9600th batch is: 9.097567\n",
            "#############################################################\n",
            "total clicks: 196613, total purchase:340292\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 15727.400000\n",
            "clicks hr ndcg @ 5 : 0.031061, 0.021625\n",
            "purchase hr and ndcg @5 : 0.042628, 0.029495\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 23246.600000\n",
            "clicks hr ndcg @ 10 : 0.045536, 0.026258\n",
            "purchase hr and ndcg @10 : 0.063052, 0.036046\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 29038.800000\n",
            "clicks hr ndcg @ 15 : 0.057087, 0.029309\n",
            "purchase hr and ndcg @15 : 0.078738, 0.040192\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 33834.400000\n",
            "clicks hr ndcg @ 20 : 0.066715, 0.031581\n",
            "purchase hr and ndcg @20 : 0.091718, 0.043257\n",
            "#############################################################\n",
            "the loss in 9800th batch is: 8.884829\n",
            "the loss in 10000th batch is: 8.939087\n",
            "the loss in 10200th batch is: 8.878780\n",
            "the loss in 10400th batch is: 8.961410\n",
            "the loss in 10600th batch is: 8.992011\n",
            "the loss in 10800th batch is: 8.572758\n",
            "the loss in 11000th batch is: 8.906301\n",
            "the loss in 11200th batch is: 9.056009\n",
            "the loss in 11400th batch is: 9.065983\n",
            "the loss in 11600th batch is: 8.770197\n",
            "the loss in 11800th batch is: 8.953305\n",
            "the loss in 12000th batch is: 8.767157\n",
            "#############################################################\n",
            "total clicks: 196613, total purchase:340292\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 17575.600000\n",
            "clicks hr ndcg @ 5 : 0.034245, 0.024023\n",
            "purchase hr and ndcg @5 : 0.047691, 0.033240\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 25388.000000\n",
            "clicks hr ndcg @ 10 : 0.049717, 0.029001\n",
            "purchase hr and ndcg @10 : 0.068861, 0.040038\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 31203.000000\n",
            "clicks hr ndcg @ 15 : 0.061695, 0.032160\n",
            "purchase hr and ndcg @15 : 0.084566, 0.044190\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 36212.800000\n",
            "clicks hr ndcg @ 20 : 0.071455, 0.034465\n",
            "purchase hr and ndcg @20 : 0.098160, 0.047399\n",
            "#############################################################\n",
            "the loss in 12200th batch is: 8.759392\n",
            "the loss in 12400th batch is: 8.709410\n",
            "the loss in 12600th batch is: 8.683157\n",
            "the loss in 12800th batch is: 9.024886\n",
            "the loss in 13000th batch is: 8.732998\n",
            "the loss in 13200th batch is: 8.984344\n",
            "the loss in 13400th batch is: 8.716845\n",
            "the loss in 13600th batch is: 8.588392\n",
            "the loss in 13800th batch is: 8.806708\n",
            "the loss in 14000th batch is: 8.709656\n",
            "the loss in 14200th batch is: 8.810410\n",
            "the loss in 14400th batch is: 8.883407\n"
          ]
        }
      ],
      "source": [
        "! python SNQN_RR_FeatureVec_new.py --model=GRU --epoch=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pksoPQy_lDXL",
        "outputId": "796e870f-f6ee-41e5-850c-059bec8dfd0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-03 06:40:26.439147: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-05-03 06:40:26.495365: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-03 06:40:27.531457: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO line 1:0: Not upgrading symbols because `tensorflow.compat.v1` was directly imported as `tf`.\n",
            "INFO line 2:0: Renamed 'tf.disable_v2_behavior' to 'tf.compat.v1.disable_v2_behavior'\n",
            "WARNING line 76:29: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "WARNING line 157:36: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "WARNING line 172:26: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "TensorFlow 2.0 Upgrade Script\n",
            "-----------------------------\n",
            "Converted 1 files\n",
            "Detected 3 issues that require attention\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "File: /content/drive/MyDrive/HM/SNQN.py\n",
            "--------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/HM/SNQN.py:76:29: WARNING: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "/content/drive/MyDrive/HM/SNQN.py:157:36: WARNING: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "/content/drive/MyDrive/HM/SNQN.py:172:26: WARNING: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "\n",
            "\n",
            "Make sure to read the detailed log 'report_SNQN_FeatureVec.txt'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!tf_upgrade_v2 \\\n",
        "  --infile '/content/drive/MyDrive/HM/SNQN.py' \\\n",
        "  --outfile '/content/drive/MyDrive/HM/SNQN_new.py' \\\n",
        "  --reportfile report_SNQN_FeatureVec.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcuregszIjZJ",
        "outputId": "a26c649f-185f-4a63-f281-253f5bb1cbc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-03 06:40:41.369646: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-05-03 06:40:41.423250: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-03 06:40:42.505992: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "/content/drive/.shortcut-targets-by-id/1HIjrgz2KrB4wLCZasrYeKTXkE-b6--I_/HM/SNQN_new.py:80: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n",
            "WARNING:tensorflow:From /content/drive/.shortcut-targets-by-id/1HIjrgz2KrB4wLCZasrYeKTXkE-b6--I_/HM/SNQN_new.py:79: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/layers/rnn/legacy_cells.py:584: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/layers/rnn/legacy_cells.py:598: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "/content/drive/.shortcut-targets-by-id/1HIjrgz2KrB4wLCZasrYeKTXkE-b6--I_/HM/SNQN_new.py:207: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(\n",
            "/content/drive/.shortcut-targets-by-id/1HIjrgz2KrB4wLCZasrYeKTXkE-b6--I_/HM/SNQN_new.py:211: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2 = tf.compat.v1.layers.dense(\n",
            "2023-05-03 06:41:07.762790: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-05-03 06:41:07.762866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38286 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n",
            "2023-05-03 06:41:07.780408: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
            "2023-05-03 06:41:12.829904: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
            "#############################################################\n",
            "total clicks: 196613, total purchase:340292\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 41.000000\n",
            "clicks hr ndcg @ 5 : 0.000153, 0.000085\n",
            "purchase hr and ndcg @5 : 0.000103, 0.000059\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 80.400000\n",
            "clicks hr ndcg @ 10 : 0.000264, 0.000121\n",
            "purchase hr and ndcg @10 : 0.000206, 0.000092\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 127.200000\n",
            "clicks hr ndcg @ 15 : 0.000412, 0.000160\n",
            "purchase hr and ndcg @15 : 0.000326, 0.000124\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 188.200000\n",
            "clicks hr ndcg @ 20 : 0.000488, 0.000178\n",
            "purchase hr and ndcg @20 : 0.000497, 0.000164\n",
            "#############################################################\n",
            "Epoch #:  0\n",
            "the loss in 200th batch is: 9.712395\n",
            "the loss in 400th batch is: 9.672754\n",
            "the loss in 600th batch is: 9.663350\n",
            "the loss in 800th batch is: 9.538610\n",
            "the loss in 1000th batch is: 9.313120\n",
            "the loss in 1200th batch is: 9.195191\n",
            "the loss in 1400th batch is: 9.243683\n",
            "the loss in 1600th batch is: 9.165661\n",
            "the loss in 1800th batch is: 9.201180\n",
            "the loss in 2000th batch is: 9.288117\n",
            "the loss in 2200th batch is: 9.057060\n",
            "the loss in 2400th batch is: 9.022328\n",
            "#############################################################\n",
            "total clicks: 196613, total purchase:340292\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 6597.400000\n",
            "clicks hr ndcg @ 5 : 0.013514, 0.009019\n",
            "purchase hr and ndcg @5 : 0.017826, 0.011755\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 10561.000000\n",
            "clicks hr ndcg @ 10 : 0.020955, 0.011409\n",
            "purchase hr and ndcg @10 : 0.028614, 0.015224\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 13775.000000\n",
            "clicks hr ndcg @ 15 : 0.027109, 0.013030\n",
            "purchase hr and ndcg @15 : 0.037347, 0.017533\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 16571.200000\n",
            "clicks hr ndcg @ 20 : 0.032938, 0.014407\n",
            "purchase hr and ndcg @20 : 0.044891, 0.019314\n",
            "#############################################################\n",
            "the loss in 2600th batch is: 9.014315\n",
            "the loss in 2800th batch is: 9.108109\n",
            "the loss in 3000th batch is: 9.075154\n",
            "the loss in 3200th batch is: 8.936088\n",
            "the loss in 3400th batch is: 9.032705\n",
            "the loss in 3600th batch is: 9.025832\n",
            "the loss in 3800th batch is: 8.836327\n",
            "the loss in 4000th batch is: 8.933254\n",
            "the loss in 4200th batch is: 8.749129\n",
            "the loss in 4400th batch is: 9.044424\n",
            "the loss in 4600th batch is: 8.698127\n",
            "the loss in 4800th batch is: 8.714811\n",
            "#############################################################\n",
            "total clicks: 196613, total purchase:340292\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 13396.800000\n",
            "clicks hr ndcg @ 5 : 0.025960, 0.018272\n",
            "purchase hr and ndcg @5 : 0.036369, 0.025288\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 19858.800000\n",
            "clicks hr ndcg @ 10 : 0.038522, 0.022312\n",
            "purchase hr and ndcg @10 : 0.053907, 0.030919\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 24699.800000\n",
            "clicks hr ndcg @ 15 : 0.048313, 0.024905\n",
            "purchase hr and ndcg @15 : 0.067001, 0.034379\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 28753.800000\n",
            "clicks hr ndcg @ 20 : 0.056527, 0.026843\n",
            "purchase hr and ndcg @20 : 0.077965, 0.036966\n",
            "#############################################################\n",
            "the loss in 5000th batch is: 8.748592\n",
            "the loss in 5200th batch is: 8.546702\n",
            "the loss in 5400th batch is: 8.861900\n",
            "the loss in 5600th batch is: 8.640036\n",
            "the loss in 5800th batch is: 8.673706\n",
            "the loss in 6000th batch is: 8.641411\n",
            "the loss in 6200th batch is: 8.484142\n",
            "the loss in 6400th batch is: 8.599159\n",
            "the loss in 6600th batch is: 8.729973\n",
            "the loss in 6800th batch is: 8.519154\n",
            "the loss in 7000th batch is: 8.610702\n",
            "the loss in 7200th batch is: 8.652114\n",
            "#############################################################\n",
            "total clicks: 196613, total purchase:340292\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 17113.600000\n",
            "clicks hr ndcg @ 5 : 0.033813, 0.024407\n",
            "purchase hr and ndcg @5 : 0.046384, 0.032985\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 24546.400000\n",
            "clicks hr ndcg @ 10 : 0.047947, 0.028947\n",
            "purchase hr and ndcg @10 : 0.066593, 0.039483\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 29901.800000\n",
            "clicks hr ndcg @ 15 : 0.058714, 0.031793\n",
            "purchase hr and ndcg @15 : 0.081086, 0.043310\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 34453.800000\n",
            "clicks hr ndcg @ 20 : 0.067920, 0.033964\n",
            "purchase hr and ndcg @20 : 0.093399, 0.046219\n",
            "#############################################################\n",
            "the loss in 7400th batch is: 8.308398\n",
            "the loss in 7600th batch is: 8.738371\n",
            "the loss in 7800th batch is: 8.499101\n",
            "the loss in 8000th batch is: 8.654232\n",
            "the loss in 8200th batch is: 8.375226\n",
            "the loss in 8400th batch is: 8.435684\n",
            "the loss in 8600th batch is: 8.647566\n",
            "the loss in 8800th batch is: 8.600876\n",
            "the loss in 9000th batch is: 8.686303\n",
            "the loss in 9200th batch is: 8.566853\n",
            "the loss in 9400th batch is: 8.478208\n",
            "the loss in 9600th batch is: 8.501670\n",
            "#############################################################\n",
            "total clicks: 196613, total purchase:340292\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 19325.400000\n",
            "clicks hr ndcg @ 5 : 0.038156, 0.027404\n",
            "purchase hr and ndcg @5 : 0.052381, 0.037142\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 27311.000000\n",
            "clicks hr ndcg @ 10 : 0.053354, 0.032281\n",
            "purchase hr and ndcg @10 : 0.074092, 0.044113\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 33136.400000\n",
            "clicks hr ndcg @ 15 : 0.065214, 0.035415\n",
            "purchase hr and ndcg @15 : 0.089840, 0.048275\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 38086.200000\n",
            "clicks hr ndcg @ 20 : 0.075127, 0.037755\n",
            "purchase hr and ndcg @20 : 0.103241, 0.051438\n",
            "#############################################################\n",
            "the loss in 9800th batch is: 8.247508\n",
            "the loss in 10000th batch is: 8.293378\n",
            "the loss in 10200th batch is: 8.439702\n",
            "the loss in 10400th batch is: 8.311255\n",
            "the loss in 10600th batch is: 8.560099\n",
            "the loss in 10800th batch is: 8.388416\n",
            "the loss in 11000th batch is: 8.501450\n",
            "the loss in 11200th batch is: 8.250434\n",
            "the loss in 11400th batch is: 8.279686\n",
            "the loss in 11600th batch is: 8.267265\n",
            "the loss in 11800th batch is: 8.301771\n",
            "the loss in 12000th batch is: 8.353875\n",
            "#############################################################\n",
            "total clicks: 196613, total purchase:340292\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 21048.000000\n",
            "clicks hr ndcg @ 5 : 0.041325, 0.029778\n",
            "purchase hr and ndcg @5 : 0.057077, 0.040634\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 29517.400000\n",
            "clicks hr ndcg @ 10 : 0.058094, 0.035178\n",
            "purchase hr and ndcg @10 : 0.080028, 0.048030\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 35729.600000\n",
            "clicks hr ndcg @ 15 : 0.070229, 0.038380\n",
            "purchase hr and ndcg @15 : 0.096882, 0.052481\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 40880.200000\n",
            "clicks hr ndcg @ 20 : 0.080646, 0.040838\n",
            "purchase hr and ndcg @20 : 0.110814, 0.055770\n",
            "#############################################################\n",
            "the loss in 12200th batch is: 8.533954\n",
            "the loss in 12400th batch is: 8.560059\n",
            "the loss in 12600th batch is: 8.515074\n",
            "the loss in 12800th batch is: 8.194948\n",
            "the loss in 13000th batch is: 8.335057\n",
            "the loss in 13200th batch is: 8.701935\n",
            "the loss in 13400th batch is: 8.321869\n",
            "the loss in 13600th batch is: 8.279764\n",
            "the loss in 13800th batch is: 8.444745\n",
            "the loss in 14000th batch is: 8.359582\n",
            "the loss in 14200th batch is: 8.485109\n",
            "the loss in 14400th batch is: 8.281797\n",
            "#############################################################\n",
            "total clicks: 196613, total purchase:340292\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 22443.000000\n",
            "clicks hr ndcg @ 5 : 0.044605, 0.032133\n",
            "purchase hr and ndcg @5 : 0.060798, 0.043379\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 31363.200000\n",
            "clicks hr ndcg @ 10 : 0.061598, 0.037592\n",
            "purchase hr and ndcg @10 : 0.085048, 0.051176\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 37869.200000\n",
            "clicks hr ndcg @ 15 : 0.073805, 0.040818\n",
            "purchase hr and ndcg @15 : 0.102756, 0.055854\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 43135.800000\n",
            "clicks hr ndcg @ 20 : 0.084018, 0.043230\n",
            "purchase hr and ndcg @20 : 0.117052, 0.059231\n",
            "#############################################################\n",
            "the loss in 14600th batch is: 8.224674\n",
            "the loss in 14800th batch is: 8.392925\n",
            "the loss in 15000th batch is: 8.369531\n",
            "the loss in 15200th batch is: 8.278071\n",
            "the loss in 15400th batch is: 8.524413\n",
            "the loss in 15600th batch is: 8.312348\n",
            "the loss in 15800th batch is: 8.221279\n",
            "the loss in 16000th batch is: 8.358362\n",
            "the loss in 16200th batch is: 8.202590\n",
            "the loss in 16400th batch is: 8.175259\n",
            "the loss in 16600th batch is: 8.407476\n",
            "Epoch #:  1\n",
            "the loss in 16800th batch is: 8.304820\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1HIjrgz2KrB4wLCZasrYeKTXkE-b6--I_/HM/SNQN_new.py\", line 433, in <module>\n",
            "    evaluate(sess)\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1HIjrgz2KrB4wLCZasrYeKTXkE-b6--I_/HM/SNQN_new.py\", line 271, in evaluate\n",
            "    eval_sessions=pd.read_pickle(os.path.join(data_directory, 'sampled_val.df'))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/io/pickle.py\", line 190, in read_pickle\n",
            "    with get_handle(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\", line 865, in get_handle\n",
            "    handle = open(handle, ioargs.mode)\n",
            "OSError: [Errno 107] Transport endpoint is not connected: 'data/sampled_val.df'\n"
          ]
        }
      ],
      "source": [
        "! python SNQN_new.py --model=GRU --epoch=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2wvc2NGwEAz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}